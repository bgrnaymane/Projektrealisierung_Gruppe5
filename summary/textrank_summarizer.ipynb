{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_rank(text, compression_rate):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sort_dict = {}\n",
    "    for i in range(len(sentences)):\n",
    "        sort_dict[i] = sentences[i]\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "        preprocessed_sentences.append(words)\n",
    "    \n",
    "    # Load pre-trained Word2Vec model\n",
    "    w2v_model = KeyedVectors.load_word2vec_format('../models/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "    \n",
    "    # Function to calculate the average word embedding for a sentence\n",
    "    def get_sentence_embedding(sentence):\n",
    "        embeddings = [w2v_model[word] for word in sentence if word in w2v_model]\n",
    "        if not embeddings:\n",
    "            return None\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    \n",
    "    sentence_embeddings = [get_sentence_embedding(sentence) for sentence in preprocessed_sentences]\n",
    "    sentence_embeddings = np.array(sentence_embeddings)\n",
    "    \n",
    "    similarity_matrix = np.dot(sentence_embeddings, sentence_embeddings.T) / (\n",
    "        np.linalg.norm(sentence_embeddings, axis=1, keepdims=True) * np.linalg.norm(sentence_embeddings, axis=1)\n",
    "    )\n",
    "    \n",
    "    damping_factor = 0.85  \n",
    "    scores = np.ones(len(sentences))\n",
    "    prev_scores = np.zeros(len(sentences))\n",
    "    while np.sum(np.abs(scores - prev_scores)) > 0.001:\n",
    "        prev_scores = np.copy(scores)\n",
    "        for i in range(len(sentences)):\n",
    "            scores[i] = (1 - damping_factor) + damping_factor * np.sum(similarity_matrix[:, i] * scores) / np.sum(similarity_matrix[:, i])\n",
    "\n",
    "    ranked_sentences = sorted(([scores[i], sentence] for i, sentence in enumerate(sentences)), reverse=True)\n",
    "    max_words = len(word_tokenize(text)) * (1-compression_rate)\n",
    "    words=0\n",
    "    chosen_texts = []\n",
    "    for text in ranked_sentences:\n",
    "        if words<=max_words:\n",
    "            sen_length = len(word_tokenize(text[1])) # https://www.guru99.com/tokenize-words-sentences-nltk.html\n",
    "            words += sen_length\n",
    "            chosen_texts.append(text[1])\n",
    "    chosen_dict = {}\n",
    "    for i in range(len(sort_dict)):\n",
    "        for text in chosen_texts:\n",
    "            if sort_dict[i] == text:\n",
    "                chosen_dict[i] = text\n",
    "    summary_sentences = chosen_dict.values()\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c5/2zgnc0p131qddyd091x_x8w00000gn/T/ipykernel_19314/2356465635.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sentence_embeddings = np.array(sentence_embeddings)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c5/2zgnc0p131qddyd091x_x8w00000gn/T/ipykernel_19314/4244782615.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Das ist ein Text.m shjasja. ajksjkas'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/c5/2zgnc0p131qddyd091x_x8w00000gn/T/ipykernel_19314/2356465635.py\u001b[0m in \u001b[0;36mtext_rank\u001b[0;34m(text, compression_rate)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msentence_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     similarity_matrix = np.dot(sentence_embeddings, sentence_embeddings.T) / (\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "print(text_rank('''The World Cup co-host looked to have earned itself a route back into the game midway through the second half when Jacqui Hand’s looping header floated over a despairing Olivia McDaniel in goal, but it was later ruled out by the video assistant referee (VAR) for offside.\n",
    "\n",
    "The World Cup debutant was able to withstand New Zealand pressure, including a truly remarkable diving save from McDaniel in added time at the end of the game, to earn a historic victory, sparking scenes of jubilant celebrations.\n",
    "\n",
    "“I literally can’t put it into words,” Bolden said afterwards. “This has been a dream of mine as a little kid to just be here at the World Cup, let alone even score.\n",
    "\n",
    "“I couldn’t have done it without my teammates, the staff, the fans, the Philippines as a whole. It’s just amazing right now to feel this win and this energy in this stadium right now, so it’s just amazing.”''', 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have heard nothing from the Ambassador about...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>I have heard nothing from the Ambassador about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think it is in the public interest to procee...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>I think it is in the public interest to procee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The A-11 aircraft now at Edwards Air force Bas...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>for example, one of the most important technic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is one of the most comprehensive bills in t...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>It is one of the most comprehensive bills in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So long as there remains a man without a job, ...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>No American conscience can be at peace while a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text             Class  \\\n",
       "0  I have heard nothing from the Ambassador about...  Political speech   \n",
       "1  I think it is in the public interest to procee...  Political speech   \n",
       "2  The A-11 aircraft now at Edwards Air force Bas...  Political speech   \n",
       "3  It is one of the most comprehensive bills in t...  Political speech   \n",
       "4  So long as there remains a man without a job, ...  Political speech   \n",
       "\n",
       "                                             Summary  \n",
       "0  I have heard nothing from the Ambassador about...  \n",
       "1  I think it is in the public interest to procee...  \n",
       "2  for example, one of the most important technic...  \n",
       "3  It is one of the most comprehensive bills in t...  \n",
       "4  No American conscience can be at peace while a...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Result/reference_summaries_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_rouge_scores(df):\n",
    "    rouge = Rouge()\n",
    "\n",
    "    rouge_scores = {\n",
    "        'all_classes': {\n",
    "            'rouge-1': {\n",
    "                'f': [],\n",
    "                'p': [],\n",
    "                'r': []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Get unique classes\n",
    "    classes = df['Class'].unique()\n",
    "\n",
    "    for cls in classes:\n",
    "        rouge_scores[cls] = {\n",
    "            'rouge-1': {\n",
    "                'f': [],\n",
    "                'p': [],\n",
    "                'r': []\n",
    "            }\n",
    "        }\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['Text']\n",
    "        reference_summary = row['Summary']\n",
    "        cls = row['Class']\n",
    "\n",
    "\n",
    "        # Generate summary with compression rate\n",
    "        compression_rate = len(reference_summary.split()) / len(text.split())\n",
    "        summary = text_rank(text, compression_rate=compression_rate)\n",
    "\n",
    "        # calculate rouge 1\n",
    "        rouge_scores_all = rouge.get_scores(summary, reference_summary)[0]\n",
    "        rouge_scores_cls = rouge_scores[cls]\n",
    "\n",
    "        # Add rouge score values\n",
    "        rouge_scores_all_cls = rouge_scores_cls['rouge-1']\n",
    "        rouge_scores_all_cls['f'].append(rouge_scores_all['rouge-1']['f'])\n",
    "        rouge_scores_all_cls['p'].append(rouge_scores_all['rouge-1']['p'])\n",
    "        rouge_scores_all_cls['r'].append(rouge_scores_all['rouge-1']['r'])\n",
    "\n",
    "        # Add rouge score values for all classes\n",
    "        rouge_scores_all_all = rouge_scores['all_classes']['rouge-1']\n",
    "        rouge_scores_all_all['f'].append(rouge_scores_all['rouge-1']['f'])\n",
    "        rouge_scores_all_all['p'].append(rouge_scores_all['rouge-1']['p'])\n",
    "        rouge_scores_all_all['r'].append(rouge_scores_all['rouge-1']['r'])\n",
    "\n",
    "    return rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all strings\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df['Summary'] = df['Summary'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c5/2zgnc0p131qddyd091x_x8w00000gn/T/ipykernel_46965/2356465635.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sentence_embeddings = np.array(sentence_embeddings)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c5/2zgnc0p131qddyd091x_x8w00000gn/T/ipykernel_46965/2778597635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrouge_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_rouge_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# calculate ROUGE-1-Scores for all classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROUGE-1 Scores für alle Klassen:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrouge_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c5/2zgnc0p131qddyd091x_x8w00000gn/T/ipykernel_46965/3683135674.py\u001b[0m in \u001b[0;36mevaluate_rouge_scores\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Generate summary with compression rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mcompression_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# calculate rouge 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c5/2zgnc0p131qddyd091x_x8w00000gn/T/ipykernel_46965/2356465635.py\u001b[0m in \u001b[0;36mtext_rank\u001b[0;34m(text, compression_rate)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msentence_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     similarity_matrix = np.dot(sentence_embeddings, sentence_embeddings.T) / (\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "rouge_scores = evaluate_rouge_scores(df)\n",
    "\n",
    "# calculate ROUGE-1-Scores for all classes\n",
    "print(\"ROUGE-1 Scores für alle Klassen:\")\n",
    "print(rouge_scores['all_classes']['rouge-1'])\n",
    "\n",
    "# calculate ROUGE-1-Scores for each class\n",
    "for cls, scores in rouge_scores.items():\n",
    "    if cls != 'all_classes':\n",
    "        print(f\"ROUGE-1 Scores für Klasse {cls}:\")\n",
    "        print(scores['rouge-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 Scores für alle Klassen:\n",
      "F1-Score Durchschnitt für alle Klassen: 0.51 (Min: 0.00, Max: 1.00)\n",
      "Precision Durchschnitt für alle Klassen: 0.67 (Min: 0.00, Max: 1.00)\n",
      "Recall Durchschnitt für alle Klassen: 0.55 (Min: 0.00, Max: 1.00)\n",
      "ROUGE-1 Scores für Klasse Political speech:\n",
      "F1-Score Durchschnitt für Klasse Political speech: 0.52 (Min: 0.00, Max: 0.99)\n",
      "Precision Durchschnitt für Klasse Political speech: 0.67 (Min: 0.00, Max: 1.00)\n",
      "Recall Durchschnitt für Klasse Political speech: 0.55 (Min: 0.00, Max: 1.00)\n",
      "ROUGE-1 Scores für Klasse News:\n",
      "F1-Score Durchschnitt für Klasse News: 0.51 (Min: 0.12, Max: 0.87)\n",
      "Precision Durchschnitt für Klasse News: 0.64 (Min: 0.16, Max: 1.00)\n",
      "Recall Durchschnitt für Klasse News: 0.56 (Min: 0.07, Max: 1.00)\n",
      "ROUGE-1 Scores für Klasse Jurisdiction:\n",
      "F1-Score Durchschnitt für Klasse Jurisdiction: 0.55 (Min: 0.14, Max: 0.98)\n",
      "Precision Durchschnitt für Klasse Jurisdiction: 0.68 (Min: 0.08, Max: 1.00)\n",
      "Recall Durchschnitt für Klasse Jurisdiction: 0.59 (Min: 0.10, Max: 1.00)\n",
      "ROUGE-1 Scores für Klasse Literature:\n",
      "F1-Score Durchschnitt für Klasse Literature: 0.50 (Min: 0.07, Max: 0.91)\n",
      "Precision Durchschnitt für Klasse Literature: 0.68 (Min: 0.14, Max: 1.00)\n",
      "Recall Durchschnitt für Klasse Literature: 0.52 (Min: 0.04, Max: 1.00)\n",
      "ROUGE-1 Scores für Klasse Blog:\n",
      "F1-Score Durchschnitt für Klasse Blog: 0.50 (Min: 0.00, Max: 1.00)\n",
      "Precision Durchschnitt für Klasse Blog: 0.68 (Min: 0.00, Max: 1.00)\n",
      "Recall Durchschnitt für Klasse Blog: 0.53 (Min: 0.00, Max: 1.00)\n"
     ]
    }
   ],
   "source": [
    "# calculate avg, max, min for all classes\n",
    "print(\"ROUGE-1 Scores für alle Klassen:\")\n",
    "all_classes_scores = rouge_scores['all_classes']['rouge-1']\n",
    "all_classes_f1_avg = sum(all_classes_scores['f']) / len(all_classes_scores['f'])\n",
    "all_classes_p_avg = sum(all_classes_scores['p']) / len(all_classes_scores['p'])\n",
    "all_classes_r_avg = sum(all_classes_scores['r']) / len(all_classes_scores['r'])\n",
    "all_classes_f1_min = min(all_classes_scores['f'])\n",
    "all_classes_p_min = min(all_classes_scores['p'])\n",
    "all_classes_r_min = min(all_classes_scores['r'])\n",
    "all_classes_f1_max = max(all_classes_scores['f'])\n",
    "all_classes_p_max = max(all_classes_scores['p'])\n",
    "all_classes_r_max = max(all_classes_scores['r'])\n",
    "print(f\"F1-Score Durchschnitt für alle Klassen: {all_classes_f1_avg:.2f} (Min: {all_classes_f1_min:.2f}, Max: {all_classes_f1_max:.2f})\")\n",
    "print(f\"Precision Durchschnitt für alle Klassen: {all_classes_p_avg:.2f} (Min: {all_classes_p_min:.2f}, Max: {all_classes_p_max:.2f})\")\n",
    "print(f\"Recall Durchschnitt für alle Klassen: {all_classes_r_avg:.2f} (Min: {all_classes_r_min:.2f}, Max: {all_classes_r_max:.2f})\")\n",
    "\n",
    "# calculate avg, max, min for each class\n",
    "for cls, scores in rouge_scores.items():\n",
    "    if cls != 'all_classes':\n",
    "        print(f\"ROUGE-1 Scores für Klasse {cls}:\")\n",
    "        class_scores = scores['rouge-1']\n",
    "        class_f1_avg = sum(class_scores['f']) / len(class_scores['f'])\n",
    "        class_p_avg = sum(class_scores['p']) / len(class_scores['p'])\n",
    "        class_r_avg = sum(class_scores['r']) / len(class_scores['r'])\n",
    "        class_f1_min = min(class_scores['f'])\n",
    "        class_p_min = min(class_scores['p'])\n",
    "        class_r_min = min(class_scores['r'])\n",
    "        class_f1_max = max(class_scores['f'])\n",
    "        class_p_max = max(class_scores['p'])\n",
    "        class_r_max = max(class_scores['r'])\n",
    "        print(f\"F1-Score Durchschnitt für Klasse {cls}: {class_f1_avg:.2f} (Min: {class_f1_min:.2f}, Max: {class_f1_max:.2f})\")\n",
    "        print(f\"Precision Durchschnitt für Klasse {cls}: {class_p_avg:.2f} (Min: {class_p_min:.2f}, Max: {class_p_max:.2f})\")\n",
    "        print(f\"Recall Durchschnitt für Klasse {cls}: {class_r_avg:.2f} (Min: {class_r_min:.2f}, Max: {class_r_max:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
