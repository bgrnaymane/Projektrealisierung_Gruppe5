{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_rank(text, compression_rate):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sort_dict = {}\n",
    "    for i in range(len(sentences)):\n",
    "        sort_dict[i] = sentences[i]\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "        preprocessed_sentences.append(' '.join(words))\n",
    "    \n",
    "    vectorizer = CountVectorizer().fit_transform(preprocessed_sentences)\n",
    "    similarity_matrix = cosine_similarity(vectorizer)\n",
    "    \n",
    "    damping_factor = 0.85  \n",
    "    scores = np.ones(len(sentences))\n",
    "    prev_scores = np.zeros(len(sentences))\n",
    "    while np.sum(np.abs(scores - prev_scores)) > 0.001:\n",
    "        prev_scores = np.copy(scores)\n",
    "        for i in range(len(sentences)):\n",
    "            scores[i] = (1 - damping_factor) + damping_factor * np.sum(similarity_matrix[:, i] * scores) / np.sum(similarity_matrix[:, i])\n",
    "    ranked_sentences = sorted(([scores[i], sentence] for i, sentence in enumerate(sentences)), reverse=True)\n",
    "    max_words = len(word_tokenize(text)) * (1-compression_rate)\n",
    "    words=0\n",
    "    chosen_texts = []\n",
    "    for text in ranked_sentences:\n",
    "        if words<=max_words:\n",
    "            sen_length = len(word_tokenize(text[1])) # https://www.guru99.com/tokenize-words-sentences-nltk.html\n",
    "            words += sen_length\n",
    "            chosen_texts.append(text[1])\n",
    "    chosen_dict = {}\n",
    "    for i in range(len(sort_dict)):\n",
    "        for text in chosen_texts:\n",
    "            if sort_dict[i] == text:\n",
    "                chosen_dict[i] = text\n",
    "    summary_sentences = chosen_dict.values()\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 'Es ist wild']\n",
      "[1.0, 'Es ist warm.']\n",
      "[1.0, 'Das ist so.']\n",
      "[1.0, 'Das ist ein Test.']\n",
      "['Es ist wild', 'Es ist warm.']\n",
      "{1: 'Es ist warm.', 3: 'Es ist wild'}\n",
      "Es ist warm. Es ist wild\n",
      "Es ist warm. Es ist wild\n"
     ]
    }
   ],
   "source": [
    "print(text_rank('Das ist ein Test. Es ist warm. Das ist so. Es ist wild', 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have heard nothing from the Ambassador about...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>I have heard nothing from the Ambassador about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think it is in the public interest to procee...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>I think it is in the public interest to procee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The A-11 aircraft now at Edwards Air force Bas...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>for example, one of the most important technic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is one of the most comprehensive bills in t...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>It is one of the most comprehensive bills in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So long as there remains a man without a job, ...</td>\n",
       "      <td>Political speech</td>\n",
       "      <td>No American conscience can be at peace while a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text             Class  \\\n",
       "0  I have heard nothing from the Ambassador about...  Political speech   \n",
       "1  I think it is in the public interest to procee...  Political speech   \n",
       "2  The A-11 aircraft now at Edwards Air force Bas...  Political speech   \n",
       "3  It is one of the most comprehensive bills in t...  Political speech   \n",
       "4  So long as there remains a man without a job, ...  Political speech   \n",
       "\n",
       "                                             Summary  \n",
       "0  I have heard nothing from the Ambassador about...  \n",
       "1  I think it is in the public interest to procee...  \n",
       "2  for example, one of the most important technic...  \n",
       "3  It is one of the most comprehensive bills in t...  \n",
       "4  No American conscience can be at peace while a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Result/reference_summaries_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/Blogs_result/blogsresult_just_textrank.csv\")\n",
    "df2 = pd.read_csv(\"../data/Blogs_result/blogsresult_refsummarys.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 scores:\n",
      "Min: 0.0\n",
      "Mean: 0.6212928899612717\n",
      "Max: 0.999999995\n",
      "Rouge-2 scores:\n",
      "Min: 0.0\n",
      "Mean: 0.5479318105729233\n",
      "Max: 0.999999995\n",
      "Rouge-L scores:\n",
      "Min: 0.0\n",
      "Mean: 0.615398270271077\n",
      "Max: 0.999999995\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "rouge_1_scores = []\n",
    "rouge_2_scores = []\n",
    "rouge_l_scores = []\n",
    "\n",
    "for idx, row1 in df1.iterrows():\n",
    "    summary1 = str(row1['Summary'])\n",
    "    \n",
    "    row2 = df2.loc[idx]\n",
    "    summary2 = str(row2['Summary'])\n",
    "    \n",
    "    scores = rouge.get_scores(summary1, summary2)[0]\n",
    "    \n",
    "    rouge_1 = scores['rouge-1']['f']\n",
    "    rouge_2 = scores['rouge-2']['f']\n",
    "    rouge_l = scores['rouge-l']['f']\n",
    "    \n",
    "    rouge_1_scores.append(rouge_1)\n",
    "    rouge_2_scores.append(rouge_2)\n",
    "    rouge_l_scores.append(rouge_l)\n",
    "\n",
    "min_rouge_1 = min(rouge_1_scores)\n",
    "mean_rouge_1 = sum(rouge_1_scores) / len(rouge_1_scores)\n",
    "max_rouge_1 = max(rouge_1_scores)\n",
    "\n",
    "min_rouge_2 = min(rouge_2_scores)\n",
    "mean_rouge_2 = sum(rouge_2_scores) / len(rouge_2_scores)\n",
    "max_rouge_2 = max(rouge_2_scores)\n",
    "\n",
    "min_rouge_l = min(rouge_l_scores)\n",
    "mean_rouge_l = sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "max_rouge_l = max(rouge_l_scores)\n",
    "\n",
    "print(\"Rouge-1 scores:\")\n",
    "print(f\"Min: {min_rouge_1}\")\n",
    "print(f\"Mean: {mean_rouge_1}\")\n",
    "print(f\"Max: {max_rouge_1}\")\n",
    "\n",
    "print(\"Rouge-2 scores:\")\n",
    "print(f\"Min: {min_rouge_2}\")\n",
    "print(f\"Mean: {mean_rouge_2}\")\n",
    "print(f\"Max: {max_rouge_2}\")\n",
    "\n",
    "print(\"Rouge-L scores:\")\n",
    "print(f\"Min: {min_rouge_l}\")\n",
    "print(f\"Mean: {mean_rouge_l}\")\n",
    "print(f\"Max: {max_rouge_l}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
