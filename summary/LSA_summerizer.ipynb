{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ4ZggPCdC8u"
      },
      "outputs": [],
      "source": [
        "# https://spacy.io/usage\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sources used in this file: \n",
        "- https://iq.opengenus.org/latent-semantic-analysis-for-text-summarization/\n",
        "- https://towardsdatascience.com/document-summarization-using-latent-semantic-indexing-b747ef2d2af6\n",
        "- https://github.com/luisfredgs/LSA-Text-Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k3I9FnPadF68"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load Spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "739vJspBXZ7u"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jAJeDJGeYm_H"
      },
      "outputs": [],
      "source": [
        "# Function for Tokenization, Remove stopwords, Lowercasing, Lemmatization, Remove punctuation\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Remove stopwords, Lowercasing, Lemmatization, Remove punctuation\n",
        "    preprocessed_tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "    # Return the preprocessed tokens as text\n",
        "    preprocessed_text = \" \".join(preprocessed_tokens)\n",
        "    return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BrEZB-HKbzfI"
      },
      "outputs": [],
      "source": [
        "def lsa_summarizer(text, compression_rate):\n",
        "    # Split text sentence\n",
        "    sentences = sent_tokenize(text) # https://www.guru99.com/tokenize-words-sentences-nltk.html\n",
        "    sort_dict = {}\n",
        "    for i in range(len(sentences)):\n",
        "        sort_dict[i] = sentences[i]\n",
        "\n",
        "    # Text Vectorization\n",
        "    vectorizer = CountVectorizer()\n",
        "    term_document_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "    # LSA-Model\n",
        "    num_components = max(int(len(sentences) * compression_rate), 1)\n",
        "    lsa_model = TruncatedSVD(n_components=num_components)\n",
        "    lsa_matrix = lsa_model.fit_transform(term_document_matrix)\n",
        "\n",
        "    # Ranking sentences\n",
        "    sentence_scores = lsa_matrix.sum(axis=1)\n",
        "    ranking = sorted(range(len(sentence_scores)), key=lambda x: sentence_scores[x], reverse=True)\n",
        "\n",
        "    ranking_texts = [sort_dict[index] for index in ranking]\n",
        "\n",
        "    max_words = len(word_tokenize(text)) * (1-compression_rate)\n",
        "    words=0\n",
        "    chosen_texts = []\n",
        "    for text in ranking_texts:\n",
        "        if words<=max_words:\n",
        "            sen_length = len(word_tokenize(text)) # https://www.guru99.com/tokenize-words-sentences-nltk.html\n",
        "            words += sen_length\n",
        "            chosen_texts.append(text)\n",
        "    \n",
        "    chosen_dict = {}\n",
        "    for i in range (len(sort_dict)):\n",
        "        for text in chosen_texts:\n",
        "            if sort_dict[i] == text:\n",
        "                chosen_dict[i] = text\n",
        "\n",
        "    summary_sentences = chosen_dict.values()\n",
        "    summary = ' '.join(summary_sentences)\n",
        "\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "taTzacn4Lsiv"
      },
      "outputs": [],
      "source": [
        "from rouge import Rouge\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_rouge_scores(df):\n",
        "    rouge = Rouge()\n",
        "\n",
        "    rouge_scores = {\n",
        "        'all_classes': {\n",
        "            'rouge-1': {\n",
        "                'f': [],\n",
        "                'p': [],\n",
        "                'r': []\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Get unique classes\n",
        "    classes = df['Class'].unique()\n",
        "\n",
        "    for cls in classes:\n",
        "        rouge_scores[cls] = {\n",
        "            'rouge-1': {\n",
        "                'f': [],\n",
        "                'p': [],\n",
        "                'r': []\n",
        "            }\n",
        "        }\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        text = row['Text']\n",
        "        reference_summary = row['Summary']\n",
        "        cls = row['Class']\n",
        "\n",
        "\n",
        "        # Generate summary with compression rate\n",
        "        compression_rate = len(reference_summary.split()) / len(text.split())\n",
        "        summary = lsa_summarizer(text, compression_rate=compression_rate)\n",
        "\n",
        "        # calculate rouge 1\n",
        "        rouge_scores_all = rouge.get_scores(summary, reference_summary)[0]\n",
        "        rouge_scores_cls = rouge_scores[cls]\n",
        "\n",
        "        # Add rouge score values\n",
        "        rouge_scores_all_cls = rouge_scores_cls['rouge-1']\n",
        "        rouge_scores_all_cls['f'].append(rouge_scores_all['rouge-1']['f'])\n",
        "        rouge_scores_all_cls['p'].append(rouge_scores_all['rouge-1']['p'])\n",
        "        rouge_scores_all_cls['r'].append(rouge_scores_all['rouge-1']['r'])\n",
        "\n",
        "        # Add rouge score values for all classes\n",
        "        rouge_scores_all_all = rouge_scores['all_classes']['rouge-1']\n",
        "        rouge_scores_all_all['f'].append(rouge_scores_all['rouge-1']['f'])\n",
        "        rouge_scores_all_all['p'].append(rouge_scores_all['rouge-1']['p'])\n",
        "        rouge_scores_all_all['r'].append(rouge_scores_all['rouge-1']['r'])\n",
        "\n",
        "    return rouge_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kt4C66V9JsHE",
        "outputId": "f4730252-48e8-4d3c-c5f6-27b31a5de6f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have heard nothing from the Ambassador about...</td>\n",
              "      <td>Political speech</td>\n",
              "      <td>I have heard nothing from the Ambassador about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I think it is in the public interest to procee...</td>\n",
              "      <td>Political speech</td>\n",
              "      <td>I think it is in the public interest to procee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The A-11 aircraft now at Edwards Air force Bas...</td>\n",
              "      <td>Political speech</td>\n",
              "      <td>for example, one of the most important technic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It is one of the most comprehensive bills in t...</td>\n",
              "      <td>Political speech</td>\n",
              "      <td>It is one of the most comprehensive bills in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So long as there remains a man without a job, ...</td>\n",
              "      <td>Political speech</td>\n",
              "      <td>No American conscience can be at peace while a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text             Class  \\\n",
              "0  I have heard nothing from the Ambassador about...  Political speech   \n",
              "1  I think it is in the public interest to procee...  Political speech   \n",
              "2  The A-11 aircraft now at Edwards Air force Bas...  Political speech   \n",
              "3  It is one of the most comprehensive bills in t...  Political speech   \n",
              "4  So long as there remains a man without a job, ...  Political speech   \n",
              "\n",
              "                                             Summary  \n",
              "0  I have heard nothing from the Ambassador about...  \n",
              "1  I think it is in the public interest to procee...  \n",
              "2  for example, one of the most important technic...  \n",
              "3  It is one of the most comprehensive bills in t...  \n",
              "4  No American conscience can be at peace while a...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data\n",
        "import pandas as pd\n",
        "\n",
        "# Read Dataframe\n",
        "df = pd.read_csv('../data/Result/reference_summaries_dataset.csv')\n",
        "\n",
        "# Show Dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tx7VvT21uXio"
      },
      "outputs": [],
      "source": [
        "# make sure all strings\n",
        "df['Text'] = df['Text'].astype(str)\n",
        "df['Summary'] = df['Summary'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p4RSIzOn9QeD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:268: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.explained_variance_ratio_ = exp_var / full_var\n"
          ]
        }
      ],
      "source": [
        "rouge_scores = evaluate_rouge_scores(df)\n",
        "\n",
        "# calculate ROUGE-1-Scores for all classes\n",
        "print(\"ROUGE-1 Scores für alle Klassen:\")\n",
        "print(rouge_scores['all_classes']['rouge-1'])\n",
        "\n",
        "# calculate ROUGE-1-Scores for each class\n",
        "for cls, scores in rouge_scores.items():\n",
        "    if cls != 'all_classes':\n",
        "        print(f\"ROUGE-1 Scores für Klasse {cls}:\")\n",
        "        print(scores['rouge-1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AXSNGcV6qXS",
        "outputId": "05703f40-6833-4fd4-8491-49880319c67a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE-1 Scores für alle Klassen:\n",
            "F1-Score Durchschnitt für alle Klassen: 0.30 (Min: 0.00, Max: 0.72)\n",
            "Precision Durchschnitt für alle Klassen: 0.34 (Min: 0.00, Max: 0.82)\n",
            "Recall Durchschnitt für alle Klassen: 0.29 (Min: 0.00, Max: 0.81)\n",
            "ROUGE-1 Scores für Klasse Political speech:\n",
            "F1-Score Durchschnitt für Klasse Political speech: 0.33 (Min: 0.00, Max: 0.58)\n",
            "Precision Durchschnitt für Klasse Political speech: 0.37 (Min: 0.00, Max: 0.66)\n",
            "Recall Durchschnitt für Klasse Political speech: 0.32 (Min: 0.00, Max: 0.54)\n",
            "ROUGE-1 Scores für Klasse News:\n",
            "F1-Score Durchschnitt für Klasse News: 0.25 (Min: 0.00, Max: 0.50)\n",
            "Precision Durchschnitt für Klasse News: 0.29 (Min: 0.00, Max: 0.62)\n",
            "Recall Durchschnitt für Klasse News: 0.24 (Min: 0.00, Max: 0.42)\n",
            "ROUGE-1 Scores für Klasse Jurisdiction:\n",
            "F1-Score Durchschnitt für Klasse Jurisdiction: 0.33 (Min: 0.05, Max: 0.52)\n",
            "Precision Durchschnitt für Klasse Jurisdiction: 0.36 (Min: 0.04, Max: 0.67)\n",
            "Recall Durchschnitt für Klasse Jurisdiction: 0.33 (Min: 0.06, Max: 0.45)\n",
            "ROUGE-1 Scores für Klasse Literature:\n",
            "F1-Score Durchschnitt für Klasse Literature: 0.28 (Min: 0.01, Max: 0.66)\n",
            "Precision Durchschnitt für Klasse Literature: 0.33 (Min: 0.01, Max: 0.67)\n",
            "Recall Durchschnitt für Klasse Literature: 0.27 (Min: 0.01, Max: 0.66)\n",
            "ROUGE-1 Scores für Klasse Blog:\n",
            "F1-Score Durchschnitt für Klasse Blog: 0.32 (Min: 0.00, Max: 0.72)\n",
            "Precision Durchschnitt für Klasse Blog: 0.37 (Min: 0.00, Max: 0.82)\n",
            "Recall Durchschnitt für Klasse Blog: 0.29 (Min: 0.00, Max: 0.81)\n"
          ]
        }
      ],
      "source": [
        "# calculate avg, max, min for all classes\n",
        "print(\"ROUGE-1 Scores für alle Klassen:\")\n",
        "all_classes_scores = rouge_scores['all_classes']['rouge-1']\n",
        "all_classes_f1_avg = sum(all_classes_scores['f']) / len(all_classes_scores['f'])\n",
        "all_classes_p_avg = sum(all_classes_scores['p']) / len(all_classes_scores['p'])\n",
        "all_classes_r_avg = sum(all_classes_scores['r']) / len(all_classes_scores['r'])\n",
        "all_classes_f1_min = min(all_classes_scores['f'])\n",
        "all_classes_p_min = min(all_classes_scores['p'])\n",
        "all_classes_r_min = min(all_classes_scores['r'])\n",
        "all_classes_f1_max = max(all_classes_scores['f'])\n",
        "all_classes_p_max = max(all_classes_scores['p'])\n",
        "all_classes_r_max = max(all_classes_scores['r'])\n",
        "print(f\"F1-Score Durchschnitt für alle Klassen: {all_classes_f1_avg:.2f} (Min: {all_classes_f1_min:.2f}, Max: {all_classes_f1_max:.2f})\")\n",
        "print(f\"Precision Durchschnitt für alle Klassen: {all_classes_p_avg:.2f} (Min: {all_classes_p_min:.2f}, Max: {all_classes_p_max:.2f})\")\n",
        "print(f\"Recall Durchschnitt für alle Klassen: {all_classes_r_avg:.2f} (Min: {all_classes_r_min:.2f}, Max: {all_classes_r_max:.2f})\")\n",
        "\n",
        "# calculate avg, max, min for each class\n",
        "for cls, scores in rouge_scores.items():\n",
        "    if cls != 'all_classes':\n",
        "        print(f\"ROUGE-1 Scores für Klasse {cls}:\")\n",
        "        class_scores = scores['rouge-1']\n",
        "        class_f1_avg = sum(class_scores['f']) / len(class_scores['f'])\n",
        "        class_p_avg = sum(class_scores['p']) / len(class_scores['p'])\n",
        "        class_r_avg = sum(class_scores['r']) / len(class_scores['r'])\n",
        "        class_f1_min = min(class_scores['f'])\n",
        "        class_p_min = min(class_scores['p'])\n",
        "        class_r_min = min(class_scores['r'])\n",
        "        class_f1_max = max(class_scores['f'])\n",
        "        class_p_max = max(class_scores['p'])\n",
        "        class_r_max = max(class_scores['r'])\n",
        "        print(f\"F1-Score Durchschnitt für Klasse {cls}: {class_f1_avg:.2f} (Min: {class_f1_min:.2f}, Max: {class_f1_max:.2f})\")\n",
        "        print(f\"Precision Durchschnitt für Klasse {cls}: {class_p_avg:.2f} (Min: {class_p_min:.2f}, Max: {class_p_max:.2f})\")\n",
        "        print(f\"Recall Durchschnitt für Klasse {cls}: {class_r_avg:.2f} (Min: {class_r_min:.2f}, Max: {class_r_max:.2f})\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
