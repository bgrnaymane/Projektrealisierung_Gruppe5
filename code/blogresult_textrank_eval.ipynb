{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code script reads blog text data, applies the TextRank algorithm for text summarization with different compression rates, and generates summaries for each blog. It then evaluates the generated summaries using Rouge metrics by comparing them to reference summaries. The script saves the generated summaries as a new CSV file and computes the minimum, mean, and maximum Rouge scores, providing an analysis of the summarization quality. Overall, the script performs text summarization and evaluates the effectiveness of the approach using Rouge metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (2.13.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (1.25.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: packaging in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgrnaymane/Documents/GitHub/Projektrealisierung_Gruppe5/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "import os\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Blogs_result/dataset.csv\")\n",
    "df = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approach TextRankSummarizer was used for 100.00% of the summaries.\n",
      "The compression rate 0.1 was used for 24.51% of the summaries.\n",
      "The compression rate 0.3 was used for 24.14% of the summaries.\n",
      "The compression rate 0.5 was used for 25.24% of the summaries.\n",
      "The compression rate 0.7 was used for 26.10% of the summaries.\n"
     ]
    }
   ],
   "source": [
    "text_rank_summarizer = TextRankSummarizer()\n",
    "\n",
    "compression_rates = [0.1, 0.3, 0.5, 0.7]  \n",
    "\n",
    "approach_counts = {summarizer.__class__.__name__: 0 for summarizer in [text_rank_summarizer]}\n",
    "compression_rate_counts = {rate: 0 for rate in compression_rates}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    approach = random.choice([text_rank_summarizer])\n",
    "    compression_rate = random.choice(compression_rates)\n",
    "    \n",
    "    approach_counts[approach.__class__.__name__] += 1\n",
    "    compression_rate_counts[compression_rate] += 1\n",
    "\n",
    "    tokenizer = Tokenizer(\"english\")\n",
    "    sentences = tokenizer.to_sentences(row['Text'])\n",
    "\n",
    "    num_sentences = int(len(sentences) * compression_rate)\n",
    "\n",
    "    summarizer = approach\n",
    "    parser = PlaintextParser.from_string(row['Text'], tokenizer)\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "\n",
    "    df.loc[index, 'Summary'] = ' '.join(str(sentence) for sentence in summary)\n",
    "\n",
    "\n",
    "total_summaries = len(df)\n",
    "\n",
    "approach_percentages = {approach: (count / total_summaries) * 100 for approach, count in approach_counts.items()}\n",
    "compression_rate_percentages = {rate: (count / total_summaries) * 100 for rate, count in compression_rate_counts.items()}\n",
    "\n",
    "for approach, percentage in approach_percentages.items():\n",
    "    print(f\"The approach {approach} was used for {percentage:.2f}% of the summaries.\")\n",
    "\n",
    "for rate, percentage in compression_rate_percentages.items():\n",
    "    print(f\"The compression rate {rate} was used for {percentage:.2f}% of the summaries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4528 entries, 0 to 4527\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Text     4528 non-null   object\n",
      " 1   Summary  4528 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 70.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have heard nothing from the Ambassador about...</td>\n",
       "      <td>Q. Mr. President, in answering an earlier ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think it is in the public interest to procee...</td>\n",
       "      <td>Intensive negotiation--day and night negotiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The A-11 aircraft now at Edwards Air force Bas...</td>\n",
       "      <td>for example, one of the most important technic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is one of the most comprehensive bills in t...</td>\n",
       "      <td>It is one of the most comprehensive bills in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So long as there remains a man without a job, ...</td>\n",
       "      <td>So long as there remains a man without a job, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  I have heard nothing from the Ambassador about...   \n",
       "1  I think it is in the public interest to procee...   \n",
       "2  The A-11 aircraft now at Edwards Air force Bas...   \n",
       "3  It is one of the most comprehensive bills in t...   \n",
       "4  So long as there remains a man without a job, ...   \n",
       "\n",
       "                                             Summary  \n",
       "0  Q. Mr. President, in answering an earlier ques...  \n",
       "1  Intensive negotiation--day and night negotiati...  \n",
       "2  for example, one of the most important technic...  \n",
       "3  It is one of the most comprehensive bills in t...  \n",
       "4  So long as there remains a man without a job, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as CSV file at: ../data/Blogs_result//blogsresult_just_textrank.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "folder_path = '../data/Blogs_result/'\n",
    "\n",
    "file_name = 'blogsresult_just_textrank.csv'\n",
    "\n",
    "file_path = folder_path + '/' + file_name\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame saved as CSV file at: {file_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/Blogs_result/blogsresult_just_textrank.csv\")\n",
    "df2 = pd.read_csv(\"../data/Blogs_result/blogsresult_refsummarys.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 scores:\n",
      "Min: 0.0\n",
      "Mean: 0.6212928899612717\n",
      "Max: 0.999999995\n",
      "Rouge-2 scores:\n",
      "Min: 0.0\n",
      "Mean: 0.5479318105729233\n",
      "Max: 0.999999995\n",
      "Rouge-L scores:\n",
      "Min: 0.0\n",
      "Mean: 0.615398270271077\n",
      "Max: 0.999999995\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "rouge_1_scores = []\n",
    "rouge_2_scores = []\n",
    "rouge_l_scores = []\n",
    "\n",
    "for idx, row1 in df1.iterrows():\n",
    "    summary1 = str(row1['Summary'])\n",
    "    \n",
    "    row2 = df2.loc[idx]\n",
    "    summary2 = str(row2['Summary'])\n",
    "    \n",
    "    scores = rouge.get_scores(summary1, summary2)[0]\n",
    "    \n",
    "    rouge_1 = scores['rouge-1']['f']\n",
    "    rouge_2 = scores['rouge-2']['f']\n",
    "    rouge_l = scores['rouge-l']['f']\n",
    "    \n",
    "    rouge_1_scores.append(rouge_1)\n",
    "    rouge_2_scores.append(rouge_2)\n",
    "    rouge_l_scores.append(rouge_l)\n",
    "\n",
    "min_rouge_1 = min(rouge_1_scores)\n",
    "mean_rouge_1 = sum(rouge_1_scores) / len(rouge_1_scores)\n",
    "max_rouge_1 = max(rouge_1_scores)\n",
    "\n",
    "min_rouge_2 = min(rouge_2_scores)\n",
    "mean_rouge_2 = sum(rouge_2_scores) / len(rouge_2_scores)\n",
    "max_rouge_2 = max(rouge_2_scores)\n",
    "\n",
    "min_rouge_l = min(rouge_l_scores)\n",
    "mean_rouge_l = sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "max_rouge_l = max(rouge_l_scores)\n",
    "\n",
    "print(\"Rouge-1 scores:\")\n",
    "print(f\"Min: {min_rouge_1}\")\n",
    "print(f\"Mean: {mean_rouge_1}\")\n",
    "print(f\"Max: {max_rouge_1}\")\n",
    "\n",
    "print(\"Rouge-2 scores:\")\n",
    "print(f\"Min: {min_rouge_2}\")\n",
    "print(f\"Mean: {mean_rouge_2}\")\n",
    "print(f\"Max: {max_rouge_2}\")\n",
    "\n",
    "print(\"Rouge-L scores:\")\n",
    "print(f\"Min: {min_rouge_l}\")\n",
    "print(f\"Mean: {mean_rouge_l}\")\n",
    "print(f\"Max: {max_rouge_l}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
