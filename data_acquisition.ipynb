{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presidential Speeches - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to ./data/Speeches/presidential-speeches.json successfully.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://millercenter.org/sites/default/files/corpus/presidential-speeches.json\"\n",
    "filename = \"./data/Speeches/presidential-speeches.json\"\n",
    "\n",
    "# Get request to the url\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    json_data = response.json()\n",
    "\n",
    "    # Save the JSON data to a file\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(json_data, file)\n",
    "\n",
    "    print(f\"JSON data saved to {filename} successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n"
     ]
    }
   ],
   "source": [
    "with open('./data/Speeches/presidential-speeches.json', 'r') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "speech_texts = [element[\"transcript\"] for element in data if len(element[\"transcript\"].split())>=1100]\n",
    "print(len(speech_texts))\n",
    "for i in range(len(speech_texts)):\n",
    "    speech_texts[i] = speech_texts[i].replace(\"\\r\\n\\r\\n\", \" \")\n",
    "    speech_texts[i] = speech_texts[i].replace(\"\\r\\n\", \"\")\n",
    "    if (len(speech_texts[i]))<=1400:\n",
    "       print(len(speech_texts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_texts_short = []\n",
    "\n",
    "for text in speech_texts:\n",
    "    target_word_count = random.randint(500, 800)\n",
    "    total_word_count = 0\n",
    "    selected_sentences = []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    sentence_length = []\n",
    "    for sentence in sentences:\n",
    "        sentence_length.append(len(sentence.split()))\n",
    "\n",
    "    max_skip = (len(sentences)*int(mean(sentence_length)))-target_word_count\n",
    "    words_to_skip = random.randint(0, max_skip)\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "\n",
    "        if total_word_count + len(words) <= words_to_skip:\n",
    "            total_word_count += len(words)\n",
    "            continue\n",
    "        if total_word_count + len(words) <= target_word_count + words_to_skip:\n",
    "            selected_sentences.append(sentence)\n",
    "            total_word_count += len(words)\n",
    "        else:\n",
    "            break\n",
    "    speech_texts_short.append(' '.join(selected_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_class = ['Political speech'] * len(speech_texts_short)\n",
    "\n",
    "df_speeches = pd.DataFrame({'Text': speech_texts_short, 'Class': speech_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These reductions come as a result of the cost-cutting programs which I asked each agency head to put into effect last November and December. The results represent some progress in our drive to raise the efficiency of the Federal Government and to cut the cost. Details will be available from Mr. Salinger. Today I have a report on the first results of our efforts to reduce the cost of Government publications. With only a few agencies reporting, with the bulk of the work yet to be done over the next several months, it is gratifying to note that already we have eliminated 158 existing or proposed publications for savings of more than $1 million to the taxpayers. I will be glad to take any questions. Q. Mr President, Soviet officials have told an American delegation that they would like to sign a long-term trade agreement with the United States. Do you favor more wheat sales to the Soviet Union, and do you favor a long-term trade agreement with the U.S.S.R.? THE PRESIDENT. We would be very happy to explore that possibility with them. We have already concluded a wheat sale to them, and if they need additional wheat or anything else we have, we would be glad to discuss it with the appropriate officials at the appropriate time. I know of few things that the Soviet Union has that we are in need of, but it is a matter that we would be glad to pursue. Q. Mr. President, do you think it is appropriate to test public sentiment for potential Vice Presidential nominees in party primaries? THE PRESIDENT. I think that that is a proper subject for the people to pass upon. I think that that is one of the reasons we have primaries, to ascertain the sentiment of the public. We are going to have a very interesting report from New Hampshire in the next few days, and I am looking forward to hearing it. I don't know that the other States will necessarily be guided by what the judgment of the New Hampshire people will be, but it will be interesting. Q. Mr. President, having been a busy Vice President yourself, and succeeding to the Presidency, would you favor a constitutional amendment as soon as possible for two Vice Presidents? THE PRESIDENT. That is a matter that is being studied by the Senate committee at this time. I would not make such a recommendation. I think the Senate committee will hear from all who are interested in the subject, and after due deliberations make their recommendations. A constitutional amendment would not be something the President would pass upon. I have individual views on it, but at this time I think it is a matter that more appropriately should be considered by the subcommittee that is considering constitutional amendments. Q. Mr. President, in view of the physical dangers to which the dependents of the U.S. military have been subjected in Saigon, has a decision been made yet as to moving them out? THE PRESIDENT. No, Secretary McNamara will no doubt have some observations to make on that question when he returns to this country, but no decision has yet been made. Q. Mr. President, speaking of Vice Presidents, among those whom you might consider acceptable and qualified for the job, how would you rate Attorney General Robert Kennedy? THE PRESIDENT.\n"
     ]
    }
   ],
   "source": [
    "print(speech_texts_short[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644.7315855181024\n"
     ]
    }
   ],
   "source": [
    "# Print the average number of words in each text\n",
    "array = []\n",
    "for transcript in speech_texts_short:\n",
    "    words = transcript.split()\n",
    "    num_words = len(words)\n",
    "    array.append(num_words)\n",
    "print(mean(array))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN News - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/Users/bnnlukas/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaf2490d5974f7786e2e0b0eb59a26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the News-Dataset from Huggingface\n",
    "news_dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 1000 texts of the dataset\n",
    "dataset_news = news_dataset['train']\n",
    "news_texts = dataset_news['article'][:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGHDAD, Iraq (CNN) -- Dressed in a Superman shirt, 5-year-old Youssif held his sister's hand Friday, seemingly unaware that millions of people across the world have been touched by his story. Nearby, his parents talked about the new future and hope they have for their boy -- and the potential for recovery from his severe burns. Youssif holds his sister's hand Friday. He's wearing a facial mask often used to help burn victims. It's the best birthday present the Iraqi family could ever have imagined for their boy: Youssif turns 6 next Friday. \"I was so happy I didn't know what to do with myself,\" his mother, Zainab, told CNN, a broad smile across her face. \"I didn't think the reaction would be this big.\" His father said he was on the roof of his house when CNN called him with the news about the outpouring of support for his son. \"We just want to thank everyone who has come forward,\" he said. \"We knew there was kindness out there.\" Like his wife, he couldn't stop smiling. He talked about how he tried in vain to get help for his son in Baghdad, leaving \"no stone unturned\" on a mission to help his boy. There were many trips to the Ministry of Health. He says he even put in a request to Iraq's parliament for help. The family eventually told CNN their story -- that Youssif was grabbed by masked men outside their home on January 15, doused in gasoline and set on fire. Simply by coming forward, his parents put themselves in incredible danger. No one has been arrested or held accountable in Youssif's case.  Watch CNN's Arwa Damon describe 'truly phenomenal' outpouring » . Shortly after Youssif's story aired Wednesday, the Children's Burn Foundation -- a nonprofit organization based in Sherman Oaks, California, that provides support for burn victims locally, nationally and internationally -- agreed to pay for the transportation for Youssif and his family to come to the United States and to set up a fund for donations. You can make a donation at the foundation's site by clicking here. There's a drop-down menu under the \"general donation\" area that is marked \"Youssif's fund.\" The foundation says it will cover all medical costs -- from surgeries for Youssif to housing costs to any social rehabilitation that might be needed for him. Surgeries will be performed by Dr. Peter Grossman, a plastic surgeon with the affiliated Grossman Burn Center who is donating his services for Youssif's cause. Officials are still trying to get the appropriate visas for the family's travels. \"We are prepared to have them come here, set them up in a housing situation, provide support for them and begin treatment,\" said Barbara Friedman, executive director of the Children's Burn Foundation. \"We expect that the treatment will be from between six months to a year with many surgeries.\" She added, \"He will be getting the absolute best care that's available.\" Youssif's parents said they know it's going to be a lengthy and difficult process and that adjusting to their stay in America may not be easy. But none of that matters -- getting help for their boy is first and foremost. \"I will do anything for Youssif,\" his father said, pulling his son closer to him. \"Our child is everything.\" His mother tried to coax Youssif to talk to us on this day. But he didn't want to; his mother says he's shy outside of their home. The biggest obstacle now is getting the visas to leave, and the serious security risks they face every day and hour they remain in Iraq. But this family -- which saw the very worst in humanity on that January day -- has new hope in the world. That is partly due to the tens of thousands of CNN.com users who were so moved by the story and wanted to act. CNN Iraqi staff central to bringing this story together were also overwhelmed with the generosity coming from people outside of their border. In a nation that largely feels abandoned by the rest of the world, it was a refreshing realization. E-mail to a friend . CNN.com senior producer Wayne Drash contributed to this report in Atlanta.\n"
     ]
    }
   ],
   "source": [
    "news_texts_long = []\n",
    "for text in news_texts:\n",
    "    if len(text.split()) >= 250:\n",
    "        news_texts_long.append(text)\n",
    "print(news_texts_long[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out the first sequuence ('BAGHDAD, Iraq (CNN) --')\n",
    "news_texts_modified = []\n",
    "for text in news_texts_long:\n",
    "    parts = text.split('--', 1)\n",
    "    if len(parts) > 1:\n",
    "        news_texts_modified.append(parts[1])  # Take the second part after the split\n",
    "    else:\n",
    "        news_texts_modified.append(text)  # Keep the original string if '--' is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dressed in a Superman shirt, 5-year-old Youssif held his sister's hand Friday, seemingly unaware that millions of people across the world have been touched by his story. Nearby, his parents talked about the new future and hope they have for their boy -- and the potential for recovery from his severe burns. Youssif holds his sister's hand Friday. He's wearing a facial mask often used to help burn victims. It's the best birthday present the Iraqi family could ever have imagined for their boy: Youssif turns 6 next Friday. \"I was so happy I didn't know what to do with myself,\" his mother, Zainab, told CNN, a broad smile across her face. \"I didn't think the reaction would be this big.\" His father said he was on the roof of his house when CNN called him with the news about the outpouring of support for his son. \"We just want to thank everyone who has come forward,\" he said. \"We knew there was kindness out there.\" Like his wife, he couldn't stop smiling. He talked about how he tried in vain to get help for his son in Baghdad, leaving \"no stone unturned\" on a mission to help his boy. There were many trips to the Ministry of Health. He says he even put in a request to Iraq's parliament for help. The family eventually told CNN their story -- that Youssif was grabbed by masked men outside their home on January 15, doused in gasoline and set on fire. Simply by coming forward, his parents put themselves in incredible danger. No one has been arrested or held accountable in Youssif's case.  Watch CNN's Arwa Damon describe 'truly phenomenal' outpouring » . Shortly after Youssif's story aired Wednesday, the Children's Burn Foundation -- a nonprofit organization based in Sherman Oaks, California, that provides support for burn victims locally, nationally and internationally -- agreed to pay for the transportation for Youssif and his family to come to the United States and to set up a fund for donations. You can make a donation at the foundation's site by clicking here. There's a drop-down menu under the \"general donation\" area that is marked \"Youssif's fund.\" The foundation says it will cover all medical costs -- from surgeries for Youssif to housing costs to any social rehabilitation that might be needed for him. Surgeries will be performed by Dr. Peter Grossman, a plastic surgeon with the affiliated Grossman Burn Center who is donating his services for Youssif's cause. Officials are still trying to get the appropriate visas for the family's travels. \"We are prepared to have them come here, set them up in a housing situation, provide support for them and begin treatment,\" said Barbara Friedman, executive director of the Children's Burn Foundation. \"We expect that the treatment will be from between six months to a year with many surgeries.\" She added, \"He will be getting the absolute best care that's available.\" Youssif's parents said they know it's going to be a lengthy and difficult process and that adjusting to their stay in America may not be easy. But none of that matters -- getting help for their boy is first and foremost. \"I will do anything for Youssif,\" his father said, pulling his son closer to him. \"Our child is everything.\" His mother tried to coax Youssif to talk to us on this day. But he didn't want to; his mother says he's shy outside of their home. The biggest obstacle now is getting the visas to leave, and the serious security risks they face every day and hour they remain in Iraq. But this family -- which saw the very worst in humanity on that January day -- has new hope in the world. That is partly due to the tens of thousands of CNN.com users who were so moved by the story and wanted to act. CNN Iraqi staff central to bringing this story together were also overwhelmed with the generosity coming from people outside of their border. In a nation that largely feels abandoned by the rest of the world, it was a refreshing realization. E-mail to a friend . CNN.com senior producer Wayne Drash contributed to this report in Atlanta.\n"
     ]
    }
   ],
   "source": [
    "print(news_texts_modified[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_class = ['News'] * len(news_texts_modified)\n",
    "\n",
    "df_news = pd.DataFrame({'Text': news_texts_modified, 'Class': news_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628.3033932135728\n"
     ]
    }
   ],
   "source": [
    "# Print the average number of words in each text\n",
    "array = []\n",
    "for text in news_texts_modified:\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    array.append(num_words)\n",
    "print(mean(array))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jurisdictions - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_jurisdictions = './data/Juristictions/'\n",
    "\n",
    "jurisdictions_texts = []\n",
    "for file_name in os.listdir(data_path_jurisdictions):\n",
    "    file_path = os.path.join(data_path_jurisdictions, file_name)\n",
    "    with open(file_path, 'r', encoding='latin-1') as file:\n",
    "        text = file.read()\n",
    "        if len(text.split()) <=3000:\n",
    "            continue\n",
    "        else:\n",
    "            jurisdictions_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "jurisdictions_texts_short = []\n",
    "\n",
    "for text in jurisdictions_texts:\n",
    "    target_word_count = random.randint(500, 800)\n",
    "    total_word_count = 0\n",
    "    selected_sentences = []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    sentence_length = []\n",
    "    for sentence in sentences:\n",
    "        sentence_length.append(len(sentence.split()))\n",
    "\n",
    "    max_skip = (len(sentences)*int(mean(sentence_length)))-target_word_count\n",
    "    words_to_skip = random.randint(0, max_skip)\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "\n",
    "        if total_word_count + len(words) <= words_to_skip:\n",
    "            total_word_count += len(words)\n",
    "            continue\n",
    "        if total_word_count + len(words) <= target_word_count + words_to_skip:\n",
    "            selected_sentences.append(sentence)\n",
    "            total_word_count += len(words)\n",
    "        else:\n",
    "            break\n",
    "    jurisdictions_texts_short.append(' '.join(selected_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651.5628205128205\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As to the alleged conspiracy, the essence of t...</td>\n",
       "      <td>Jurisdiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One can have reservations about a policy frame...</td>\n",
       "      <td>Jurisdiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Under rule 54(2) the employment tribunal or ju...</td>\n",
       "      <td>Jurisdiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The practical importance of that principle was...</td>\n",
       "      <td>Jurisdiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relying on that recommendation and the CJEUs r...</td>\n",
       "      <td>Jurisdiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text         Class\n",
       "0  As to the alleged conspiracy, the essence of t...  Jurisdiction\n",
       "1  One can have reservations about a policy frame...  Jurisdiction\n",
       "2  Under rule 54(2) the employment tribunal or ju...  Jurisdiction\n",
       "3  The practical importance of that principle was...  Jurisdiction\n",
       "4  Relying on that recommendation and the CJEUs r...  Jurisdiction"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jurisdictions_class = ['Jurisdiction'] * len(jurisdictions_texts_short)\n",
    "\n",
    "# Create the Dataframe for the jurisdictions\n",
    "df_jurisdictions = pd.DataFrame({'Text': jurisdictions_texts_short, 'Class': jurisdictions_class})\n",
    "\n",
    "array_jurisdictions = []\n",
    "for text in jurisdictions_texts_short:\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    array_jurisdictions.append(num_words)\n",
    "\n",
    "# Print the average number of words in each text\n",
    "print(mean(array_jurisdictions))\n",
    "\n",
    "# Print the first rows of the dataframe\n",
    "df_jurisdictions.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anzahl_texte = 1000\n",
    "buch_ids = []\n",
    "\n",
    "for i in range(anzahl_texte):\n",
    "        buch = random.choice(gutenberg.fileids())\n",
    "        buch_ids.append(buch)\n",
    "\n",
    "file_path = \"./data/Literature/buch_ids.txt\"\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    for item in buch_ids:\n",
    "        file.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/Literature/buch_ids.txt\"\n",
    "ausgabe_datei = './data/Literature/literarische_texte.csv'\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    buch_ids = file.read().splitlines()\n",
    "\n",
    "header = ['Titel', 'Text']\n",
    "\n",
    "with open(ausgabe_datei, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for buch in buch_ids:\n",
    "        titel = buch.replace('.txt', '')\n",
    "        text = gutenberg.raw(buch)\n",
    "        writer.writerow([titel, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lit = pd.read_csv('./data/Literature/literarische_texte.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "literature_texts = []\n",
    "for text in df_lit['Text']:\n",
    "    cleaned_text = re.sub(r'^\\[[^\\]]+\\]\\s*', '', text)\n",
    "    cleaned_text = cleaned_text.replace('\\n', ' ')\n",
    "    # Replace all multispaces with singlespaces to get texts that are more clean\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    literature_texts.append(cleaned_text)\n",
    "\n",
    "print(len(literature_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "literature_texts_short = []\n",
    "\n",
    "for text in literature_texts:\n",
    "    target_word_count = random.randint(500, 800)\n",
    "    total_word_count = 0\n",
    "    selected_sentences = []\n",
    "    sentences = nltk.sent_tokenize(text)       \n",
    "    sentence_length = []\n",
    "    for sentence in sentences:\n",
    "        sentence_length.append(len(sentence.split()))\n",
    "\n",
    "    max_skip = (len(sentences)*int(mean(sentence_length)))-target_word_count\n",
    "    words_to_skip = random.randint(0, max_skip)\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "\n",
    "        if total_word_count + len(words) <= words_to_skip:\n",
    "            total_word_count += len(words)\n",
    "            continue\n",
    "        if total_word_count + len(words) <= target_word_count + words_to_skip:\n",
    "            selected_sentences.append(sentence)\n",
    "            total_word_count += len(words)\n",
    "        else:\n",
    "            break\n",
    "    literature_texts_short.append(' '.join(selected_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It contained these words: \"DEAR MR. OAKLY,--I ...</td>\n",
       "      <td>Literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr. and Mrs. Elton, indeed, shewed no unwillin...</td>\n",
       "      <td>Literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Often, when forced from his hammock by exhaust...</td>\n",
       "      <td>Literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Queene (my Lord) is dead Macb. She should ...</td>\n",
       "      <td>Literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I see poor crazed Lucia's eyes' unnatural glea...</td>\n",
       "      <td>Literature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       Class\n",
       "0  It contained these words: \"DEAR MR. OAKLY,--I ...  Literature\n",
       "1  Mr. and Mrs. Elton, indeed, shewed no unwillin...  Literature\n",
       "2  Often, when forced from his hammock by exhaust...  Literature\n",
       "3  The Queene (my Lord) is dead Macb. She should ...  Literature\n",
       "4  I see poor crazed Lucia's eyes' unnatural glea...  Literature"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literature_class = ['Literature'] * len(literature_texts_short)\n",
    "\n",
    "# Create the Dataframe for the literature texts\n",
    "df_literature = pd.DataFrame({'Text': literature_texts_short, 'Class': literature_class})\n",
    "\n",
    "# Print the first rows of the dataframe\n",
    "df_literature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650.693\n"
     ]
    }
   ],
   "source": [
    "# Print the average number of words in each text\n",
    "array = []\n",
    "for text in literature_texts_short:\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    array.append(num_words)\n",
    "print(mean(array))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blogs - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data-Source: https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus\n",
    "df_blo = pd.read_csv('./data/Blogs/blogtext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1184.917\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "# Create array with blogs over 1000 words to cut too short blogs\n",
    "large_blog_texts = []\n",
    "array = []\n",
    "for text in df_blo['text']:\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    if 1000 <= num_words <= 1500 and n < 1000:\n",
    "        n+=1\n",
    "        large_blog_texts.append(text)\n",
    "        array.append(num_words)\n",
    "# Print the average number of words in each text\n",
    "print(n)\n",
    "print(mean(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_count = 650\n",
    "\n",
    "# Skip the first 200 words to just get clear text and not the title, the authors, the copyright, etc.\n",
    "words_to_skip = 200\n",
    "blog_texts = []\n",
    "\n",
    "for text in large_blog_texts:\n",
    "    total_word_count = 0\n",
    "    selected_sentences = []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "\n",
    "        if total_word_count + len(words) <= words_to_skip:\n",
    "            total_word_count += len(words)\n",
    "            continue\n",
    "        if total_word_count + len(words) <= target_word_count + words_to_skip:\n",
    "            selected_sentences.append(sentence)\n",
    "            total_word_count += len(words)\n",
    "        else:\n",
    "            break\n",
    "    if len(' '.join(selected_sentences).split()) >= 250:\n",
    "        blog_texts.append(' '.join(selected_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i saw one (two, actually, but one appeared to ...</td>\n",
       "      <td>Blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't help it HIM (4:38:07 PM): guess you do...</td>\n",
       "      <td>Blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italian-Australian immigrants always harken ba...</td>\n",
       "      <td>Blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your whole family is a bit embarrassed, but yo...</td>\n",
       "      <td>Blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We each buy nothing, coming back to the realit...</td>\n",
       "      <td>Blog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Class\n",
       "0  i saw one (two, actually, but one appeared to ...  Blog\n",
       "1  I can't help it HIM (4:38:07 PM): guess you do...  Blog\n",
       "2  Italian-Australian immigrants always harken ba...  Blog\n",
       "3  Your whole family is a bit embarrassed, but yo...  Blog\n",
       "4  We each buy nothing, coming back to the realit...  Blog"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_class = ['Blog'] * len(blog_texts)\n",
    "\n",
    "# Create the dataframe for the blog texts\n",
    "df_blogs = pd.DataFrame({'Text': blog_texts, 'Class': blog_class})\n",
    "\n",
    "# Print the first rows of the dataframe\n",
    "df_blogs.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These reductions come as a result of the cost-...</td>\n",
       "      <td>Political speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q. Mr. President, there have been some conflic...</td>\n",
       "      <td>Political speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now there are going to be some very serious pr...</td>\n",
       "      <td>Political speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And so far as I am concerned, I hope to keep a...</td>\n",
       "      <td>Political speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Others walk that road today, and our experienc...</td>\n",
       "      <td>Political speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text             Class\n",
       "0  These reductions come as a result of the cost-...  Political speech\n",
       "1  Q. Mr. President, there have been some conflic...  Political speech\n",
       "2  Now there are going to be some very serious pr...  Political speech\n",
       "3  And so far as I am concerned, I hope to keep a...  Political speech\n",
       "4  Others walk that road today, and our experienc...  Political speech"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the resulting dataframe for all texts with the related Classes\n",
    "result_df = pd.concat([df_speeches, df_news, df_jurisdictions, df_literature, df_blogs], ignore_index=True)\n",
    "\n",
    "# Print the first rows of the resulting dataframe \n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in result_df.iterrows():\n",
    "    text = row['Text']\n",
    "    words = text.split()\n",
    "    if len(words) < 230:\n",
    "        result_df = result_df.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645.1966353506664\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "# Print the average number of words in each text\n",
    "array = []\n",
    "for text in result_df['Text']:\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    array.append(num_words)\n",
    "print(mean(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe to a csv-File\n",
    "result_df.to_csv('./data/Result/dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
